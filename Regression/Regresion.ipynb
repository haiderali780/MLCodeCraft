{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals\n",
    "\n",
    "In this Assignmnet :\n",
    "\n",
    " - You Will impliment the regression models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools\n",
    "In this lab we will make use of: \n",
    "- NumPy, a popular library for scientific computing\n",
    "- Matplotlib, a popular library for plotting data\n",
    "- Pandas,  a Python library for data analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries\n",
    "\n",
    "![Libraries](https://github.com/ahmad-14a/CS-F20-ML/blob/main/Regression-Assignment%202/Libraries.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# import the necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Fetch Data From CSV Files\n",
    "\n",
    "![Load Data](https://github.com/ahmad-14a/CS-F20-ML/blob/main/Regression-Assignment%202/Load%20N%20show.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code Here\n",
    "#Read the trainig and testing data from the file\n",
    "train_data = pd.read_csv('trainRegression.csv')\n",
    "test_data = pd.read_csv('testRegression.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code Here\n",
    "#Show the first 5 rows of the training data\n",
    "print(train_data.head()) #head function shows the 5 rows."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Expected Output\n",
    "\n",
    "\n",
    "![Output 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/Regression-Assignment%202/O1.png?raw=true)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Type Casting of Data\n",
    "\n",
    "![TypeCasting](https://github.com/ahmad-14a/CS-F20-ML/blob/main/Regression-Assignment%202/Type%20Casting.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code Here\n",
    "#TypeCast the data into numpy array\n",
    "X_train = np.array(train_data['X'])  # Convert the 'X' column from the train_data DataFrame into a numpy array for features\n",
    "Y_train = np.array(train_data['R'])  # Convert the 'R' column from the train_data DataFrame into a numpy array for the response variable\n",
    "\n",
    "X_test = np.array(test_data['X'])  # Convert the 'X' column from the test_data DataFrame into a numpy array for features\n",
    "Y_test = np.array(test_data['R'])  # Convert the 'R' column from the test_data DataFrame into a numpy array for the response variable\n",
    " \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code Here\n",
    "#Plot your Training Data using matplotlib\n",
    "plt.plot(X_train, Y_train, color='blue')  # This will connect the points directly\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Expected Output\n",
    "\n",
    "\n",
    "![Model Equations](https://github.com/ahmad-14a/CS-F20-ML/blob/main/Regression-Assignment%202/O2.png?raw=true)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Fit Linear Regression Model (Training data)\n",
    "\n",
    " As our linear Model was\n",
    " \n",
    "![Cost Funtion](https://github.com/ahmad-14a/CS-F20-ML/blob/main/Regression-Assignment%202/Cost%20funtion1.png?raw=true\n",
    ")\n",
    "\n",
    "And using derivatives we transformed our model into 2 simultaneous equations\n",
    "\n",
    "![Model Equations](https://github.com/ahmad-14a/CS-F20-ML/blob/main/Regression-Assignment%202/Linear%20Model%20Eqs.png?raw=true)\n",
    "\n",
    "\n",
    "Then converted it in matrix form\n",
    "\n",
    "![Model Equations](https://github.com/ahmad-14a/CS-F20-ML/blob/main/Regression-Assignment%202/Linear%20Model.png?raw=true)\n",
    "\n",
    "\n",
    "\n",
    "NOTE :  Now you are required to compute values wihtout using foor loop on tarining data\n",
    "- HINT : Use numpy library for this purpose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code Here\n",
    "#For loop is not recommended in these cases, \n",
    "#use numpy functions to calculate the values of above variables in one line of code.\n",
    "#Such as x.shape for number of rows, sum() for sum of all elements in x\n",
    "#np.dot() or multiply suntion for square of x \n",
    "\n",
    "Matrix_A = np.array([\n",
    "    [X_train.shape[0], np.sum(X_train)],  # Count of samples and sum of X_train values\n",
    "    [np.sum(X_train), np.sum(np.multiply(X_train, X_train))]  # Sum of X_train values and sum of squared X_train values\n",
    "])  \n",
    "\n",
    "Matrix_B = np.array([\n",
    "    [np.sum(Y_train)],  # Sum of Y_train values\n",
    "    [np.sum(np.multiply(X_train, Y_train))]  # Sum of product of X_train and Y_train\n",
    "])  \n",
    "\n",
    "\n",
    "\n",
    "print(\"Matrix A:\")\n",
    "print(\"\\n\")\n",
    "print(Matrix_A)\n",
    "print(\"\\n\")\n",
    "print(\"Matrix B:\")\n",
    "print(\"\\n\")\n",
    "print(Matrix_B)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected output\n",
    "\n",
    "![Linear Model MAtrixes](https://github.com/ahmad-14a/CS-F20-ML/blob/main/Regression-Assignment%202/Matrixs%20Linear.png?raw=true)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Valus of Both Î˜`s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code Here\n",
    "#Calculate the values of 0_node and 0_1 using Matrix Multiplication\n",
    "#Hint: Use X = A^-1 * B to calculate the values of 0_node and 0_1\n",
    "A_inv = np.linalg.inv(Matrix_A)  # Calculate the inverse of Matrix_A\n",
    "X = np.dot(A_inv, Matrix_B)  # Perform matrix multiplication between the inverse of Matrix_A and Matrix_B to solve for X\n",
    "theta_0, theta_1 = X[0][0], X[1][0]  # Extract theta_0 and theta_1 values from the resulting X matrix\n",
    "X_Matrix = np.array([theta_0, theta_1])  # Create a numpy array containing the calculated theta_0 and theta_1\n",
    "\n",
    "print(\"Matrxi X for the linear model :\")\n",
    "print(\"\\n\")\n",
    "print(X_Matrix.reshape(2,1))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected Output\n",
    "\n",
    "![Linear Model MAtrixes](https://github.com/ahmad-14a/CS-F20-ML/blob/main/Regression-Assignment%202/Matrixs%20LinearT.png?raw=true)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Predictions (Testing data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code Here\n",
    "# In order to calculate the pridicted values of y\n",
    "# Use the formula y = 0_node + 0_1 * x\n",
    "# _____DO NOT USE FOR LOOP_____\n",
    "# instead Convert the column of test_x into numpy a 2 dimensional matrix\n",
    "# then use matrix multiplication to calculate the predicted values of y\n",
    "X_test_b = np.c_[np.ones((X_test.shape[0], 1)), X_test]  # Add a column of ones to X_test to account for the intercept term in the model\n",
    "Y_pred = X_test_b.dot(X_Matrix)  # Calculate predicted values of Y for the test set using matrix multiplication with model parameters\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Square Error"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cost Funtion](https://github.com/ahmad-14a/CS-F20-ML/blob/main/Regression-Assignment%202/Cost%20funtion1.png?raw=true\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code Here\n",
    "#Using cost function calculate the cost of the model\n",
    "mse = np.mean((Y_test - Y_pred) ** 2)  # Calculate the Mean Squared Error between actual and predicted Y values for the test set\n",
    "print(\"Mean Square Error for LINEAR MODEL:: \", mse)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected Output\n",
    "\n",
    "![MSE of Linear](https://github.com/ahmad-14a/CS-F20-ML/blob/main/Regression-Assignment%202/MSE%20Linear.png?raw=true\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Data (Train and Test Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Your code Here\n",
    "\n",
    "#FOR TRAINING DATA\n",
    "#Plot the predicted values of y against the test_x\n",
    "y_train_pred = np.dot(np.c_[np.ones((X_train.shape[0], 1)), X_train], X_Matrix)  # Calculate predictions for the training data using the model parameters\n",
    "# Plot the training data as scatter points\n",
    "plt.scatter(X_train, Y_train, color='purple', label='Train Data')\n",
    "# Plot the linear model's predictions as a line\n",
    "plt.plot(X_train, y_train_pred, color='red', label='Linear Model')\n",
    "plt.title('Linear Model for the train data')  # Set the plot title\n",
    "plt.xlabel('R')  # Label the x-axis as 'R'\n",
    "plt.ylabel('X')  # Label the y-axis as 'X'\n",
    "plt.legend()  # Display a legend to identify scatter and line plots\n",
    "plt.show()  # Display the plot\n",
    "\n",
    "#FOR TESTING DATA\n",
    "plt.scatter(X_test, Y_test, color='purple', label='Test Data')  # Plot the testing data as scatter points\n",
    "plt.plot(X_test, Y_pred, color='red', label='Linear Model')  # Plot the linear model's predictions for the test data as a line\n",
    "plt.title('Linear Model for the test data')  # Set the plot title to indicate it's for the test data\n",
    "plt.xlabel('R')  # Label the x-axis as 'R', indicating the feature or independent variable\n",
    "plt.ylabel('X')  # Label the y-axis as 'X', indicating the target or dependent variable\n",
    "plt.legend()  # Display a legend to differentiate between the test data points and the model's prediction line\n",
    "plt.show()  # Display the plot\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Outputs for Linear Model\n",
    "\n",
    "![Training Data Plot](https://github.com/ahmad-14a/CS-F20-ML/blob/main/Regression-Assignment%202/Linear%20O.png?raw=true)\n",
    "\n",
    "![Test Data Plot](https://github.com/ahmad-14a/CS-F20-ML/blob/main/Regression-Assignment%202/Linear%20O%20test.png?raw=true)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Fit The Quadratic Model\n",
    "\n",
    " As our Quadratic Model was\n",
    " \n",
    "![Cost Funtion for quadratic ](https://github.com/ahmad-14a/CS-F20-ML/blob/main/Regression-Assignment%202/Cost%20funtion2.png?raw=true\n",
    ")\n",
    "\n",
    "And using derivatives we transformed our model into 3 simultaneous equations\n",
    "\n",
    "![Model Equations of quadratic](https://github.com/ahmad-14a/CS-F20-ML/blob/main/Regression-Assignment%202/Quad%20Model%20Eqs.png?raw=true)\n",
    "\n",
    "\n",
    "Then converted it in matrix form\n",
    "\n",
    "![Model Formula of Quadratic](https://github.com/ahmad-14a/CS-F20-ML/blob/main/Regression-Assignment%202/Quad%20Model1.png?raw=true)\n",
    "\n",
    "\n",
    "\n",
    "NOTE :  Now you are required to compute values wihtout using foor loop on tarining data\n",
    "- HINT : Use numpy library for this purpose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code Here\n",
    "#For loop is not recommended in these cases, \n",
    "#use numpy functions to calculate the values of above variables in one line of code.\n",
    "#Such as x.shape for number of rows, sum() for sum of all elements in x\n",
    "#np.dot() or multiply suntion for square of x \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Matrix_A = np.array([\n",
    "    [X_train.shape[0], np.sum(X_train), np.sum(np.square(X_train))],  # Intercept, x, and x^2 counts/sums for bias term\n",
    "    [np.sum(X_train), np.sum(np.square(X_train)), np.sum(np.power(X_train, 3))],  # x sums, x^2 sums, and x^3 sums for the linear term\n",
    "    [np.sum(np.square(X_train)), np.sum(np.power(X_train, 3)), np.sum(np.power(X_train, 4))]  # x^2 sums, x^3 sums, and x^4 sums for the quadratic term\n",
    "])\n",
    "\n",
    "\n",
    "Matrix_B = np.array([\n",
    "    [np.sum(Y_train)],  # Sum of Y_train for intercept part\n",
    "    [np.sum(np.multiply(X_train, Y_train))],  # Sum of product of X_train and Y_train for linear part\n",
    "    [np.sum(np.multiply(np.square(X_train), Y_train))]  # Sum of product of X_train squared and Y_train for quadratic part\n",
    "])\n",
    "\n",
    "print(\"Matrix A :\")\n",
    "print(Matrix_A)\n",
    "print(\"\\nMatrix B :\")\n",
    "print(Matrix_B)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected Output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Quadratic Model Matrixes](https://github.com/ahmad-14a/CS-F20-ML/blob/main/Regression-Assignment%202/Matrixs%20Quad1.png?raw=true)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Valus Of Three Î˜`s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code Here\n",
    "#Calculate the values of 0_node and 0_1 using Matrix Multiplication\n",
    "#Hint: Use X = A^-1 * B to calculate the values of 0_node , 0_1 and 0_2\n",
    "A_inv = np.linalg.inv(Matrix_A)  # Calculate the inverse of Matrix_A\n",
    "X = np.dot(A_inv, Matrix_B)  # Perform matrix multiplication between the inverse of Matrix_A and Matrix_B to solve for X\n",
    "theta_0, theta_1,theta_2 = X[0][0], X[1][0] , X[2][0]  # Extract theta_0 ,theta_1,theta_2 values from the resulting X matrix\n",
    "X_Matrix = np.array([theta_0, theta_1,theta_2])  # Create a numpy array containing the calculated theta_0 and theta_1\n",
    "\n",
    "print(\"Matrxi X for the quadratic model :\")\n",
    "print(\"\\n\")\n",
    "print(X_Matrix.reshape(3,1))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected Output\n",
    "\n",
    "![Quadratic Model MAtrixes](https://github.com/ahmad-14a/CS-F20-ML/blob/main/Regression-Assignment%202/Matrixs%20Quad.png?raw=true)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Predictions (Testing data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code Here\n",
    "# In order to calculate the pridicted values of y\n",
    "# Use the formula y = 0_node + 0_1 * x\n",
    "# _____DO NOT USE FOR LOOP_____\n",
    "# instead Convert the column of test_x into numpy a 2 dimensional matrix\n",
    "# then use matrix multiplication to calculate the predicted values of y\n",
    "X_test_b = np.c_[np.ones((X_test.shape[0], 1)), X_test, X_test**2]  # Include X_test squared for the quadratic term\n",
    "# Calculate predicted values of Y for the test set using matrix multiplication with model parameters\n",
    "Y_pred = X_test_b.dot(X_Matrix)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Square Error"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Cost Funtion](https://github.com/ahmad-14a/CS-F20-ML/blob/main/Regression-Assignment%202/Cost%20funtion2.png?raw=true\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code Here\n",
    "#Using cost function calculate the cost of the model\n",
    "mse = np.mean((Y_test - Y_pred) ** 2)  # Calculate the Mean Squared Error between actual and predicted Y values for the test set\n",
    "print(\"Mean Square Error for QUADRATIC MODEL:: \", mse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected Output\n",
    "\n",
    "![MSE of Quadratic](https://github.com/ahmad-14a/CS-F20-ML/blob/main/Regression-Assignment%202/MSE%20Quad.png?raw=true\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Data (Train and Test Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Your code Here\n",
    "#Plot the predicted values of y against the test_x\n",
    "# Generate a range of X values for plotting the quadratic model curve\n",
    "X_range = np.linspace(X_train.min(), X_train.max(), 500)\n",
    "# Prepare the design matrix for the X range\n",
    "X_range_b = np.c_[np.ones((X_range.shape[0], 1)), X_range, X_range**2]\n",
    "# Calculate predictions for the plotting range\n",
    "y_range_pred = X_range_b.dot(X_Matrix)\n",
    "# Plot the training data as scatter points\n",
    "plt.scatter(X_train, Y_train, color='purple', label='Train Data')\n",
    "# Plot the quadratic model's predictions as a curve\n",
    "plt.plot(X_range, y_range_pred, color='red', label='Quadratic Model')\n",
    "plt.title('Quadratic Model for the Train Data')  # Set the plot title\n",
    "plt.xlabel('X')  # Label the x-axis as 'R'\n",
    "plt.ylabel('R')  # Label the y-axis as 'X'\n",
    "plt.legend()  # Display a legend to identify scatter and curve plots\n",
    "plt.show()  # Display the plot\n",
    "\n",
    "\n",
    "\n",
    "# For the testing data, ensure that the predictions are sorted along with the X_test for a proper curve plot\n",
    "# This is especially necessary if X_test is not already in a sorted order\n",
    "sorted_indices = np.argsort(X_test)\n",
    "sorted_X_test = X_test[sorted_indices]\n",
    "sorted_Y_pred = Y_pred[sorted_indices]\n",
    "# Plot the testing data as scatter points\n",
    "plt.scatter(X_test, Y_test, color='purple', label='Test Data')\n",
    "# Plot the quadratic model's predictions as a curve\n",
    "plt.plot(sorted_X_test, sorted_Y_pred, color='red', label='Quadratic Model')\n",
    "plt.title('Quadratic Model for the Test Data')  # Set the plot title to indicate it's for the test data\n",
    "plt.xlabel('X')  # Label the x-axis as 'R', indicating the feature or independent variable\n",
    "plt.ylabel('R')  # Label the y-axis as 'X', indicating the target or dependent variable\n",
    "plt.legend()  # Display a legend to differentiate between the test data points and the model's prediction curve\n",
    "plt.show()  # Display the plot\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Outputs for Quadratic Model\n",
    "\n",
    "![Training Data Plot](https://github.com/ahmad-14a/CS-F20-ML/blob/main/Regression-Assignment%202/Quad%20O.png?raw=true)\n",
    "\n",
    "![Test Data Plot](https://github.com/ahmad-14a/CS-F20-ML/blob/main/Regression-Assignment%202/Quad%20O%20tets.png?raw=true)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Fit The Cubic Model\n",
    "\n",
    "Cubic Model in matrix form\n",
    "\n",
    "![Model Formula of Quadratic](https://github.com/ahmad-14a/CS-F20-ML/blob/main/Regression-Assignment%202/Cubic%20Model.png?raw=true)\n",
    "\n",
    "\n",
    "\n",
    "NOTE :  Now you are required to compute values wihtout using foor loop on tarining data\n",
    "- HINT : Use numpy library for this purpose "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code Here\n",
    "#For loop is not recommended in these cases, \n",
    "#use numpy functions to calculate the values of above variables in one line of code.\n",
    "#Such as x.shape for number of rows, sum() for sum of all elements in x\n",
    "#np.dot() or multiply suntion for square of x \n",
    "\n",
    "\n",
    "# Constructing Matrix_A for a cubic regression model. It accounts for the intercept, linear, quadratic, and cubic terms.\n",
    "# The matrix includes sums of powers of X up to the sixth power, necessary for the cubic model's normal equation.\n",
    "Matrix_A = np.array([\n",
    "    [X_train.shape[0], np.sum(X_train), np.sum(np.square(X_train)), np.sum(np.power(X_train, 3))],  # Row for intercept\n",
    "    [np.sum(X_train), np.sum(np.square(X_train)), np.sum(np.power(X_train, 3)), np.sum(np.power(X_train, 4))],  # Row for linear term\n",
    "    [np.sum(np.square(X_train)), np.sum(np.power(X_train, 3)), np.sum(np.power(X_train, 4)), np.sum(np.power(X_train, 5))],  # Row for quadratic term\n",
    "    [np.sum(np.power(X_train, 3)), np.sum(np.power(X_train, 4)), np.sum(np.power(X_train, 5)), np.sum(np.power(X_train, 6))]  # Row for cubic term\n",
    "])\n",
    "\n",
    "# Constructing Matrix_B for a cubic regression model. It aligns with the outcome variable Y_train,\n",
    "# containing sums of Y_train, and products of Y_train with powers of X up to the third power.\n",
    "Matrix_B = np.array([\n",
    "    [np.sum(Y_train)],  # Sum of Y_train for intercept\n",
    "    [np.sum(np.multiply(X_train, Y_train))],  # Sum of products of X_train and Y_train for linear term\n",
    "    [np.sum(np.multiply(np.square(X_train), Y_train))],  # Sum of products of X_train squared and Y_train for quadratic term\n",
    "    [np.sum(np.multiply(np.power(X_train, 3), Y_train))]  # Sum of products of X_train cubed and Y_train for cubic term\n",
    "])\n",
    "\n",
    "# Printing Matrix_A and Matrix_B for visualization\n",
    "print(\"Matrix A for Cubic Model:\")\n",
    "print(Matrix_A)\n",
    "print(\"\\nMatrix B for Cubic Model:\")\n",
    "print(Matrix_B)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected Output\n",
    "\n",
    "![Cubic Model Matrixes](https://github.com/ahmad-14a/CS-F20-ML/blob/main/Regression-Assignment%202/Matrixs%20Cubic1.png?raw=true)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute Valus Of Four Î˜`s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code Here\n",
    "#Calculate the values of 0_node and 0_1 using Matrix Multiplication\n",
    "#Hint: Use X = A^-1 * B to calculate the values of 0_node , 0_1 ,0_2 and 0_3\n",
    "A_inv = np.linalg.inv(Matrix_A)  # Calculate the inverse of Matrix_A\n",
    "X = np.dot(A_inv, Matrix_B)  # Perform matrix multiplication between the inverse of Matrix_A and Matrix_B to solve for X\n",
    "theta_0, theta_1,theta_2,theta_3 = X[0][0], X[1][0] , X[2][0],X[3][0] # Extract theta_0 ,theta_1,theta_2,theta_3 values from the resulting X matrix\n",
    "X_Matrix = np.array([theta_0, theta_1,theta_2,theta_3])  # Create a numpy array containing the calculated theta_0,theta_1,theta_2,theta_3\n",
    "\n",
    "print(\"Matrxi X for the quadratic model :\")\n",
    "print(\"\\n\")\n",
    "print(X_Matrix.reshape(4,1))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected Output\n",
    "\n",
    "![Cubic Model MAtrixes](https://github.com/ahmad-14a/CS-F20-ML/blob/main/Regression-Assignment%202/Matrixs%20Cubic.png?raw=true)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Predictions (Testing data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code Here\n",
    "# In order to calculate the pridicted values of y\n",
    "# Use the formula y = 0_node + 0_1 * x\n",
    "# _____DO NOT USE FOR LOOP_____\n",
    "# instead Convert the column of test_x into numpy a 2 dimensional matrix\n",
    "# then use matrix multiplication to calculate the predicted values of y\n",
    "# Extend X_test_b for cubic model: Add intercept, linear, quadratic, and cubic terms\n",
    "X_test_b = np.c_[np.ones((X_test.shape[0], 1)), X_test, X_test**2, X_test**3]\n",
    "# Compute Y_pred using cubic model parameters for matrix multiplication\n",
    "Y_pred = X_test_b.dot(X_Matrix)\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Square Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code Here\n",
    "#Using cost function calculate the cost of the model\n",
    "mse = np.mean((Y_test - Y_pred) ** 2)  # Calculate the Mean Squared Error between actual and predicted Y values for the test set\n",
    "print(\"Mean Square :: \", mse)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected Output\n",
    "\n",
    "![MSE of Cubic](https://github.com/ahmad-14a/CS-F20-ML/blob/main/Regression-Assignment%202/MSE%20Cubic.png?raw=true\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Data (Train and Test Data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Your code Here\n",
    "#Plot the predicted values of y against the test_x\n",
    "# Generate a range of X values for plotting the cubic model curve\n",
    "X_range = np.linspace(X_train.min(), X_train.max(), 500)\n",
    "# Extend the design matrix for the X range to include cubic term\n",
    "X_range_b = np.c_[np.ones((X_range.shape[0], 1)), X_range, X_range**2, X_range**3]\n",
    "# Calculate predictions for the plotting range using the cubic model\n",
    "y_range_pred = X_range_b.dot(X_Matrix)\n",
    "# Plot training data as scatter points\n",
    "plt.scatter(X_train, Y_train, color='pink', label='Train Data')\n",
    "# Plot the cubic model's predictions as a curve\n",
    "plt.plot(X_range, y_range_pred, color='red', label='Cubic Model')\n",
    "plt.title('Cubic Model for the Train Data')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('R')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Ensure predictions are sorted along with X_test for a proper curve plot for the cubic model\n",
    "sorted_indices = np.argsort(X_test)\n",
    "sorted_X_test = X_test[sorted_indices]\n",
    "sorted_Y_pred = Y_pred[sorted_indices]\n",
    "# Plot testing data as scatter points\n",
    "plt.scatter(X_test, Y_test, color='purple', label='Test Data')\n",
    "# Plot the cubic model's predictions as a curve\n",
    "plt.plot(sorted_X_test, sorted_Y_pred, color='red', label='Cubic Model')\n",
    "plt.title('Cubic Model for the Test Data')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('R')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Outputs for Cubic Model\n",
    "\n",
    "![Training Data Plot](https://github.com/ahmad-14a/CS-F20-ML/blob/main/Regression-Assignment%202/Cubic%20O.png?raw=true)\n",
    "\n",
    "![Test Data Plot](https://github.com/ahmad-14a/CS-F20-ML/blob/main/Regression-Assignment%202/Cubic%20O%20test.png?raw=true)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now You Are Required To Fit Your 4 , 5 and 6 degree Models Step By Step As You Did Before"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Fit The 4 degree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code Here\n",
    "\n",
    "\n",
    "#Note: Here ,not explaining the code with comments too much because the things are same as we did above for linear,qudratic,cubic,only one more unknown theta is increased,and matrix size get change\n",
    "\n",
    "# Adjust Matrix_A for the quartic model, incorporating terms up to x^4 for features and x^8 for interactions\n",
    "Matrix_A = np.array([\n",
    "    [X_train.shape[0], np.sum(X_train), np.sum(np.square(X_train)), np.sum(np.power(X_train, 3)), np.sum(np.power(X_train, 4))],\n",
    "    [np.sum(X_train), np.sum(np.square(X_train)), np.sum(np.power(X_train, 3)), np.sum(np.power(X_train, 4)), np.sum(np.power(X_train, 5))],\n",
    "    [np.sum(np.square(X_train)), np.sum(np.power(X_train, 3)), np.sum(np.power(X_train, 4)), np.sum(np.power(X_train, 5)), np.sum(np.power(X_train, 6))],\n",
    "    [np.sum(np.power(X_train, 3)), np.sum(np.power(X_train, 4)), np.sum(np.power(X_train, 5)), np.sum(np.power(X_train, 6)), np.sum(np.power(X_train, 7))],\n",
    "    [np.sum(np.power(X_train, 4)), np.sum(np.power(X_train, 5)), np.sum(np.power(X_train, 6)), np.sum(np.power(X_train, 7)), np.sum(np.power(X_train, 8))]\n",
    "])\n",
    "\n",
    "# Adjust Matrix_B for the quartic model, aligning outcome Y_train with features up to x^4\n",
    "Matrix_B = np.array([\n",
    "    [np.sum(Y_train)],\n",
    "    [np.sum(np.multiply(X_train, Y_train))],\n",
    "    [np.sum(np.multiply(np.square(X_train), Y_train))],\n",
    "    [np.sum(np.multiply(np.power(X_train, 3), Y_train))],\n",
    "    [np.sum(np.multiply(np.power(X_train, 4), Y_train))]\n",
    "])\n",
    "\n",
    "# Printing Matrix_A and Matrix_B for visualization\n",
    "print(\"Matrix A for 4 degree Model:\")\n",
    "print(Matrix_A)\n",
    "print(\"\\nMatrix B for 4 degree Model:\")\n",
    "print(Matrix_B)\n",
    "\n",
    "\n",
    "\n",
    "A_inv = np.linalg.inv(Matrix_A)  # Calculate the inverse of Matrix_A\n",
    "X = np.dot(A_inv, Matrix_B)  # Perform matrix multiplication between the inverse of Matrix_A and Matrix_B to solve for X\n",
    "theta_0, theta_1,theta_2,theta_3,theta_4 = X[0][0], X[1][0] , X[2][0],X[3][0],X[4][0] # Extract theta_0 ,theta_1,theta_2,theta_3,theta_4 values from the resulting X matrix\n",
    "X_Matrix = np.array([theta_0, theta_1,theta_2,theta_3,theta_4])  # Create a numpy array containing the calculated theta_0,theta_1,theta_2,theta_3,theta_4\n",
    "\n",
    "print(\"Matrxi X for the quadratic model :\")\n",
    "print(\"\\n\")\n",
    "print(X_Matrix.reshape(5,1))\n",
    "\n",
    "# Extend X_test_b for quartic model: Add columns for ones (intercept), X_test (linear term), X_test squared (quadratic term),\n",
    "# X_test cubed (cubic term), and X_test to the fourth (quartic term)\n",
    "X_test_b = np.c_[np.ones((X_test.shape[0], 1)), X_test, X_test**2, X_test**3, X_test**4]\n",
    "\n",
    "# Compute Y_pred using quartic model parameters for matrix multiplication\n",
    "Y_pred = X_test_b.dot(X_Matrix)\n",
    "\n",
    "#Using cost function calculate the cost of the model\n",
    "mse = np.mean((Y_test - Y_pred) ** 2)  # Calculate the Mean Squared Error between actual and predicted Y values for the test set\n",
    "print(\"Mean Square :: \", mse)\n",
    "\n",
    "# Generate a range of X values for plotting the quartic model curve\n",
    "X_range = np.linspace(X_train.min(), X_train.max(), 500)\n",
    "# Extend the design matrix for the X range to include terms up to x^4 for the quartic model\n",
    "X_range_b = np.c_[np.ones((X_range.shape[0], 1)), X_range, X_range**2, X_range**3, X_range**4]\n",
    "# Calculate predictions for the plotting range using the quartic model\n",
    "y_range_pred = X_range_b.dot(X_Matrix)\n",
    "# Plot training data as scatter points\n",
    "plt.scatter(X_train, Y_train, color='pink', label='Train Data')\n",
    "# Plot the quartic model's predictions as a curve\n",
    "plt.plot(X_range, y_range_pred, color='red', label='Quartic Model')\n",
    "plt.title('Quartic Model for the Train Data')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# Ensure predictions are sorted along with X_test for a proper curve plot for the quartic model\n",
    "sorted_indices = np.argsort(X_test)\n",
    "sorted_X_test = X_test[sorted_indices]\n",
    "sorted_Y_pred = Y_pred[sorted_indices]\n",
    "# Plot testing data as scatter points\n",
    "plt.scatter(X_test, Y_test, color='purple', label='Test Data')\n",
    "# Plot the quartic model's predictions as a curve\n",
    "plt.plot(sorted_X_test, sorted_Y_pred, color='red', label='Quartic Model')\n",
    "plt.title('Quartic Model for the Test Data')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Fit The 5 degree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code Here\n",
    "\n",
    "# Step 1: Construct Matrix_A and Matrix_B for Quintic Model\n",
    "#Note: Here ,not explaining the code with comments too much because the things are same as we did above for linear,qudratic,cubic,only one more unknown theta is increased,and matrix size get change\n",
    "\n",
    "Matrix_A = np.array([\n",
    "    [len(X_train), np.sum(X_train), np.sum(X_train**2), np.sum(X_train**3), np.sum(X_train**4), np.sum(X_train**5)],\n",
    "    [np.sum(X_train), np.sum(X_train**2), np.sum(X_train**3), np.sum(X_train**4), np.sum(X_train**5), np.sum(X_train**6)],\n",
    "    [np.sum(X_train**2), np.sum(X_train**3), np.sum(X_train**4), np.sum(X_train**5), np.sum(X_train**6), np.sum(X_train**7)],\n",
    "    [np.sum(X_train**3), np.sum(X_train**4), np.sum(X_train**5), np.sum(X_train**6), np.sum(X_train**7), np.sum(X_train**8)],\n",
    "    [np.sum(X_train**4), np.sum(X_train**5), np.sum(X_train**6), np.sum(X_train**7), np.sum(X_train**8), np.sum(X_train**9)],\n",
    "    [np.sum(X_train**5), np.sum(X_train**6), np.sum(X_train**7), np.sum(X_train**8), np.sum(X_train**9), np.sum(X_train**10)]\n",
    "])\n",
    "\n",
    "Matrix_B = np.array([\n",
    "    [np.sum(Y_train)],\n",
    "    [np.sum(X_train * Y_train)],\n",
    "    [np.sum(X_train**2 * Y_train)],\n",
    "    [np.sum(X_train**3 * Y_train)],\n",
    "    [np.sum(X_train**4 * Y_train)],\n",
    "    [np.sum(X_train**5 * Y_train)]\n",
    "])\n",
    "\n",
    "\n",
    "# Step 2: Solve for Model Parameters\n",
    "A_inv = np.linalg.inv(Matrix_A)\n",
    "X_Matrix = np.dot(A_inv, Matrix_B).flatten()\n",
    "\n",
    "# Step 3: Prepare Test Data and Make Predictions\n",
    "X_test_b = np.c_[np.ones(len(X_test)), X_test, X_test**2, X_test**3, X_test**4, X_test**5]\n",
    "Y_pred = np.dot(X_test_b, X_Matrix)\n",
    "\n",
    "# Step 4: Calculate and Print Mean Squared Error\n",
    "mse = np.mean((Y_test - Y_pred)**2)\n",
    "print(\"Mean Square Error for Quintic Model:\", mse)\n",
    "\n",
    "# Step 5: Generate and Plot Predictions for Training Data\n",
    "X_range = np.linspace(X_train.min(), X_train.max(), 500)\n",
    "X_range_b = np.c_[np.ones(len(X_range)), X_range, X_range**2, X_range**3, X_range**4, X_range**5]\n",
    "y_range_pred = np.dot(X_range_b, X_Matrix)\n",
    "\n",
    "plt.scatter(X_train, Y_train, color='pink', label='Training Data')\n",
    "plt.plot(X_range, y_range_pred, color='red', label='Quintic Model Prediction')\n",
    "plt.title('Quintic Model for Training Data')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Step 6: Plot Predictions for Testing Data\n",
    "sorted_indices = np.argsort(X_test)\n",
    "sorted_X_test = X_test[sorted_indices]\n",
    "sorted_Y_pred = Y_pred[sorted_indices]\n",
    "\n",
    "plt.scatter(X_test, Y_test, color='purple', label='Testing Data')\n",
    "plt.plot(sorted_X_test, sorted_Y_pred, color='red', label='Quintic Model Prediction')\n",
    "plt.title('Quintic Model for Testing Data')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now Fit The 6 degree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your code Here\n",
    "#Note: Here ,not explaining the code with comments too much because the things are same as we did above for linear,qudratic,cubic,only one more unknown theta is increased,and matrix size get change\n",
    "# Constructing Matrix_A for the 6th-degree Model\n",
    "Matrix_A = np.array([\n",
    "    [len(X_train), np.sum(X_train), np.sum(X_train**2), np.sum(X_train**3), np.sum(X_train**4), np.sum(X_train**5), np.sum(X_train**6)],\n",
    "    [np.sum(X_train), np.sum(X_train**2), np.sum(X_train**3), np.sum(X_train**4), np.sum(X_train**5), np.sum(X_train**6), np.sum(X_train**7)],\n",
    "    [np.sum(X_train**2), np.sum(X_train**3), np.sum(X_train**4), np.sum(X_train**5), np.sum(X_train**6), np.sum(X_train**7), np.sum(X_train**8)],\n",
    "    [np.sum(X_train**3), np.sum(X_train**4), np.sum(X_train**5), np.sum(X_train**6), np.sum(X_train**7), np.sum(X_train**8), np.sum(X_train**9)],\n",
    "    [np.sum(X_train**4), np.sum(X_train**5), np.sum(X_train**6), np.sum(X_train**7), np.sum(X_train**8), np.sum(X_train**9), np.sum(X_train**10)],\n",
    "    [np.sum(X_train**5), np.sum(X_train**6), np.sum(X_train**7), np.sum(X_train**8), np.sum(X_train**9), np.sum(X_train**10), np.sum(X_train**11)],\n",
    "    [np.sum(X_train**6), np.sum(X_train**7), np.sum(X_train**8), np.sum(X_train**9), np.sum(X_train**10), np.sum(X_train**11), np.sum(X_train**12)]\n",
    "])\n",
    "\n",
    "# Constructing Matrix_B for the 6th-degree Model\n",
    "Matrix_B = np.array([\n",
    "    [np.sum(Y_train)],\n",
    "    [np.sum(X_train * Y_train)],\n",
    "    [np.sum(X_train**2 * Y_train)],\n",
    "    [np.sum(X_train**3 * Y_train)],\n",
    "    [np.sum(X_train**4 * Y_train)],\n",
    "    [np.sum(X_train**5 * Y_train)],\n",
    "    [np.sum(X_train**6 * Y_train)]\n",
    "])\n",
    "\n",
    "# Solving for Model Parameters\n",
    "A_inv = np.linalg.inv(Matrix_A)\n",
    "X_Matrix = np.dot(A_inv, Matrix_B).flatten()\n",
    "\n",
    "# Preparing Test Data and Making Predictions\n",
    "X_test_b = np.c_[np.ones(len(X_test)), X_test, X_test**2, X_test**3, X_test**4, X_test**5, X_test**6]\n",
    "Y_pred = np.dot(X_test_b, X_Matrix)\n",
    "\n",
    "# Calculating and Printing Mean Squared Error\n",
    "mse = np.mean((Y_test - Y_pred)**2)\n",
    "print(\"Mean Square Error for 6th-Degree Model:\", mse)\n",
    "\n",
    "# Generating and Plotting Predictions for Training Data\n",
    "X_range = np.linspace(X_train.min(), X_train.max(), 500)\n",
    "X_range_b = np.c_[np.ones(len(X_range)), X_range, X_range**2, X_range**3, X_range**4, X_range**5, X_range**6]\n",
    "y_range_pred = np.dot(X_range_b, X_Matrix)\n",
    "\n",
    "plt.scatter(X_train, Y_train, color='pink', label='Training Data')\n",
    "plt.plot(X_range, y_range_pred, color='red', label='6th-Degree Model Prediction')\n",
    "plt.title('6th-Degree Model for Training Data')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plotting Predictions for Testing Data\n",
    "sorted_indices = np.argsort(X_test)\n",
    "sorted_X_test = X_test[sorted_indices]\n",
    "sorted_Y_pred = Y_pred[sorted_indices]\n",
    "\n",
    "plt.scatter(X_test, Y_test, color='purple', label='Testing Data')\n",
    "plt.plot(sorted_X_test, sorted_Y_pred, color='red', label='6th-Degree Model Prediction')\n",
    "plt.title('6th-Degree Model for Testing Data')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comment on the results by comparing all of your models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Linear Model:** Exhibits the highest MSE, indicating insufficient complexity to capture the data's underlying patterns effectively.\n",
    "\n",
    "**2nd-degree Model:** A slight increase in MSE suggests overfitting or inadequacy in capturing the data's structure with a simple quadratic relationship.\n",
    "\n",
    "**3rd and 4th-degree Models:** Show significant improvements in MSE, highlighting the benefits of capturing more complex nonlinear relationships in the data.\n",
    "\n",
    "**5th-degree (Quintic) Model:** Achieves the lowest MSE, suggesting an optimal balance between model complexity and fitting the data's underlying patterns without excessive overfitting.\n",
    "\n",
    "**6th-degree Model:** A minor increase in MSE compared to the 5th-degree model implies that further increasing complexity slightly reduces predictive performance, possibly due to beginning overfitting or the model capturing noise in the data.\n",
    "\n",
    " >**Overall, the quintic model provides the best balance of complexity and accuracy, indicating its superiority for this specific dataset.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
